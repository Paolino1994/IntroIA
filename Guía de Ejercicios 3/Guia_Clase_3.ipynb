{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guia Clase 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+uu7a4F1sxsVZ8SydqRUT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paolino1994/IntroIA/blob/main/Gu%C3%ADa%20de%20Ejercicios%203/Guia_Clase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "hZZfHKapw2Oe"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecicio #1: Normalización\n",
        "\n",
        "Muchos algoritmos de Machine Learning necesitan datos de entrada centrados y normalizados. Una normalización habitual es el z-score, que implica restarle la media y dividir por el desvío a cada feature de mi dataset."
      ],
      "metadata": {
        "id": "WOjWTeIcwrj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zScore(X):\n",
        "  #X=np.array(X)\n",
        "  mean=X.mean(axis=0)\n",
        "  std=X.std(axis=0)\n",
        "  return (X-mean)/std"
      ],
      "metadata": {
        "id": "67Fxp9j-ws3F"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([1,80,3,55]).reshape(2,2)\n",
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "if(np.allclose(zScore(X),X_scaled)):\n",
        "  print(\"Scaler is working Great\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVNjyaABy27z",
        "outputId": "de5a8a5e-b6a0-4f1d-b325-4cb06aea37a3"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler is working Great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecicio #2: Remover filas y columnas con NaNs en un dataset\n",
        "\n",
        "Dado un dataset, hacer una función que, utilizando numpy, filtre las columnas y las filas que tienen NaNs."
      ],
      "metadata": {
        "id": "zr6TYdnE0-Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def removeNANs(X):\n",
        "  nonNANRows=~np.isnan(X).any(axis=0)\n",
        "  X=X.T[nonNANRows].T\n",
        "  nonNANColumns=~np.isnan(X).any(axis=1)\n",
        "  X=X[nonNANColumns]\n",
        "  return X"
      ],
      "metadata": {
        "id": "4P8ql8mI1Fog"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([0,1,2,3,4,5,np.NaN,7,8]).reshape(3,3)\n",
        "print(X)\n",
        "removeNANs(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYxRBZEA2GqE",
        "outputId": "500a01a6-55e8-44a6-b9e5-46972fa89817"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  1.  2.]\n",
            " [ 3.  4.  5.]\n",
            " [nan  7.  8.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [4., 5.],\n",
              "       [7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecicio #3: Reemplazar NaNs por la media de la columna\n",
        "\n",
        "Dado un dataset, hacer una función que utilizando numpy reemplace los NaNs por la media de la columna."
      ],
      "metadata": {
        "id": "HrcKmsYX3wCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceNANs(X):\n",
        "  means=np.nanmean(X, axis=0)\n",
        "  Nans = np.where(np.isnan(X))\n",
        "  X[Nans] = np.take(means, Nans[1]) \n",
        "  return X\n"
      ],
      "metadata": {
        "id": "niabrc9f3yEq"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([0,1,2,3,4,5,np.NaN,7,8]).reshape(3,3)\n",
        "replaceNANs(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHmkqvwP4PAA",
        "outputId": "dcd72ebb-97f9-4239-de1d-c4d8f23bf97b"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 1. , 2. ],\n",
              "       [3. , 4. , 5. ],\n",
              "       [1.5, 7. , 8. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecicio #4: Dado un dataset X separarlo en 70 / 20 / 10\n",
        "\n",
        "Como vimos en el ejercicio integrador, en problemas de Machine Learning es fundamental que separemos los datasets de n muestras, en 3 datasets de la siguiente manera:\n",
        "\n",
        "    Training dataset: los datos que utilizaremos para entrenar nuestros modelos. Ej: 70% de las muestras.\n",
        "    Validation dataset: los datos que usamos para calcular métricas y ajustar los hiperparámetros de nuestros modelos. Ej: 20% de las muestras.\n",
        "    Testing dataset: una vez que entrenamos los modelos y encontramos los hiperparámetros óptimos de los mísmos, el testing dataset se lo utiliza para computar las métricas finales de nuestros modelos y analizar cómo se comporta respecto a la generalización. Ej: 10% de las muestras.\n",
        "\n",
        "A partir de utilizar np.random.permutation, hacer un método que dado un dataset, devuelva los 3 datasets como nuevos numpy arrays."
      ],
      "metadata": {
        "id": "brILkN8d5a5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splitData(X):\n",
        "  Xrand=np.random.permutation(X)\n",
        "  trainQ=int(len(Xrand)*0.7)\n",
        "  testQ=int(len(Xrand)*0.2)+trainQ\n",
        "  valQ=len(Xrand)\n",
        "  return Xrand[:trainQ],Xrand[trainQ:testQ],Xrand[testQ:valQ]"
      ],
      "metadata": {
        "id": "x5nBASln5cfZ"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(range(0,300)).reshape(100,3)\n",
        "for i in splitData(X):\n",
        "  print(i.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H9qkCkK6O5C",
        "outputId": "3f1cb05b-9600-4979-8f3b-be63994a83bd"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70, 3)\n",
            "(20, 3)\n",
            "(10, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UCNZCwzH7Cr_"
      },
      "execution_count": 150,
      "outputs": []
    }
  ]
}